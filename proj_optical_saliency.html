<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Optical Remote Sensing Image Saliency</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <meta name="viewport" content="width=device-width">
  </head>
  <body>
    <div class="wrapper">
<header>
<h7>Chongyi Li</h7><br><br>
<div>
<img src="sub_img/IMG_7689.jpg" border="0" width="80%"><br></div><br>

  
<p>
<small>lichongyi25@gmail.com lichongyi@tju.edu.cn</small><br><br>
<a href="https://github.com/Li-Chongyi" target="_blank">[GitHub]</a>  
<a href="http://dblp.uni-trier.de/pers/hd/l/Li:Chongyi" target="_blank">[DBLP]</a>  <br>
<a href="https://scholar.google.com/citations?user=1_I0P-AAAAAJ&hl=zh-CN" target="_blank">[Google Scholar]</a> <br>
</p> <br>
<p class="view"><a href="https://li-chongyi.github.io/">Homepage</a></p>
<p class="view"><a href="sub_publication.html">Publications</a></p>
<p class="view"><a href="sub_projects.html">Projects</a></p>
</header>


      <section>

<h2>
<a id="project_title" class="anchor" href="#project_title" aria-hidden="true"><span class="octicon octicon-link"></span></a>Nested Network with Two-Stream Pyramid
for Salient Object Detection in Optical Remote Sensing Images</h2>




<h4>
<a id="Introduction-page" class="anchor" href="#Introduction-pages" aria-hidden="true"><span class="octicon octicon-link"></span></a>Introduction:</h4>
<div style="text-align: justify; display: block; margin-right: auto;">
<p>Arising from the various object types and scales, diverse imaging orientations, and cluttered backgrounds in optical remote sensing image (RSI), it is difficult to directly extend the success of salient object detection for nature scene image
to the optical RSI. In this paper, we propose an end-to-end deep network called LV-Net based on the shape of network architecture, which detects salient objects from optical RSIs in
a purely data-driven fashion. The proposed LV-Net consists of two key modules, i.e., a two-stream pyramid module (L-shaped module) and an encoder-decoder module with nested connections
(V-shaped module). Specifically, the L-shaped module extracts a set of complementary information hierarchically by using a two-stream pyramid structure, which is beneficial to perceiving the
diverse scales and local details of salient objects. The V-shaped module gradually integrates encoder detail features with decoder semantic features through nested connections, which aims at sup-
pressing the cluttered backgrounds and highlighting the salient objects. In addition, we construct the first publicly available optical RSI dataset for salient object detection, including 800
images with varying spatial resolutions, diverse saliency types, and pixel-wise ground truth. Experiments on this benchmark dataset demonstrate that the proposed method outperforms the
state-of-the-art salient object detection methods both qualitatively and quantitatively.
</p>

<div style="text-align: center; display: block; margin-right: auto;">
<img src="sub_img/LV-Net.png" border="0" width="600"><br></div><br>
 

<hr />
<h4>Paper:</h4>
    
<p>
  Chongyi Li, Runmin Cong, Junhui Hou, Sanyi Zhang, Yue Qian, and Sam Kwong, 
  <strong>Nested Network with Two-Stream Pyramid for Salient Object Detection in Optical Remote Sensing Images</strong>. 
  <a href="https://ieeexplore.ieee.org/document/8793227"><font color="#ff0000">PDF (TGRS, 2019)</font></a>
</p>

 
        
<h4>LV-Net Resutls: </h4>
<p>
<br><a href="https://drive.google.com/open?id=1nnZKphu9_4oBvie4yqdxG95tYZRsqj4W" target="_blank"><font color="#ff0000">[Google Drive Link]</font></a>
<a href="https://pan.baidu.com/s/1nc6ZyiFrBEo_g4YWTGaGhw" target="_blank"><font color="#ff0000">[Baidu Cloud Link]</font></a><br>
</p> 
<hr />
 
<h4>ORSSD Dataset: </h4>
<p>
<br><a href="https://drive.google.com/open?id=15FOnRo1xnz05fcNkXBhWy8WL0C26i8y4" target="_blank"><font color="#ff0000">[Google Drive Link]</font></a>
<a href="https://pan.baidu.com/s/1k44UlTLCW17AS0VhPyP7JA" target="_blank"><font color="#ff0000">[Baidu Cloud Link]</font></a><br>
<br>If you need the this dataset, please cite the related paper. Thanks.<br>
</p> 
<hr />

<!--<h4>Deep Model: </h4>
<p>
<br><a href="https://drive.google.com/open?id=10_QYTD4OfkUoB_An0pKFHXyAGPoWY0f_" target="_blank"><font color="#ff0000">[Google Drive Link]</font></a>
<a href="https://pan.baidu.com/s/18W1Tya9VDYK4o_YbqEv0MA" target="_blank"><font color="#ff0000">[Baidu Cloud Link]</font></a><br>

</p> 
<hr />-->

      </section>

    </div>
    <script src="../../javascripts/scale.fix.js"></script>
  </body>
</html>
