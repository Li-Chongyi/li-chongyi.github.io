
<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Glaucoma Screening in Fundus Image</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <meta name="viewport" content="width=device-width">
  </head>
  <body>
    <div class="wrapper">

<section>

<h3>
<a id="Back-pages" class="anchor" href="#Back-pages" aria-hidden="true"><span class="octicon octicon-link"></span></a><a href="index.html#Project-page"><ud>Back to Homepage</ud></a> </h3>

<h2>
<a id="project_title" class="anchor" href="#project_title" aria-hidden="true"><span class="octicon octicon-link"></span></a>Glaucoma Screening in Fundus Image
</h2>


<h3>Introduction:</h3>

Glaucoma is a chronic eye disease that leads to irreversible vision loss. Since vision loss from glaucoma cannot be reversed, early screening and detection methods are essential to preserve vision and life quality. One major glaucoma screening technique is optic nerve head (ONH) assessment, which employs a binary classification to identify the glaucomatous and healthy subjects.  
<br><br>

<div style="text-align: center; display: block; margin-right: auto;">
<img src="sub_img/cover_CDR.jpg" border="0" width="400"><br></div> 
Figure: Structure of the optic nerve head. The vertical cup to disc ratio (CDR) is calculated by the ratio of vertical cup diameter (VCD) to vertical disc diameter (VDD), which plays an important role in the screening and diagnosis of glaucoma. <br>

<br>

<hr/>

<h3>Glaucoma Dataset:</h3>

Due to the clinical policy, the ORIGA, SCES, and SINDI datasets cannot be released. <br>
 
However, we organized the <strong>REFUGE: Retinal Fundus Glaucoma Challenge</strong> in conjunction with the MICCAI-OMIA Workshop 2018, including disc/cup segmentation, glaucoma screening, and localization of fovea tasks. This challenge provided 1200 fundus images (400 training + 400 validation + 400 test) with pixel labels. If you are interested, you can register and download dataset from: [<a href="https://refuge.grand-challenge.org/home/" target="_blank"><font color="#E74C3C"><ud2>Link</ud2></font></a>]


<br>

<br>
<hr />

<h3>MNet: Multi-label Deep Network:</h3>

In this work, we proposed a deep learning architecture, named M-Net, which solves the OD and OC segmentation jointly in a one-stage multi-label system. The proposed M-Net mainly consists of multi-scale input layer, U-shape convolutional network, side-output layer, and multi-label loss function. The multi-scale input layer constructs an image pyramid to achieve multiple level receptive field sizes. The U-shape convolutional network is employed as the main body network structure to learn the rich hierarchical representation, while the side-output layer acts as an early classifier that produces a companion local prediction map for different scale layers. Finally, a multi-label loss function is proposed to generate the final segmentation map.
<br> <br>

<strong>Reference:</strong><br>

Huazhu Fu,  Jun Cheng, Yanwu Xu, Damon Wing Kee Wong, Jiang Liu, and Xiaochun Cao,  <strong>"Joint Optic Disc and Cup Segmentation Based on Multi-label Deep Network and Polar Transformation"</strong>, 
<em>IEEE Transactions on Medical Imaging (TMI)</em>, vol. 37, no. 7, pp. 1597-1605, 2018.  <br>  
<a href="https://arxiv.org/abs/1801.00926" target="_blank">[PDF]</a>  
<a href="https://github.com/HzFu/MNet_DeepCDR" target="_blank"><font color="#ff0000">[Code]</font></a> 
<br><br>

<div style="text-align: center; display: block; margin-right: auto;">
<img src="sub_img/framework_MNet.jpg" border="0" width="600"><br></div> 
Figure: Our M-Net architecture consists of multi-scale input layer, U-shape convolutional network, side-output layer, and multi-label loss function.<br>

<br>
<hr/>

<h3>DENet: Disc-aware Ensemble Network:</h3>

In this work, we introduce a deep learning technique to gain additional image-relevant information, and screen glaucoma from the fundus image directly. Specifically, a novel Disc-aware Ensemble Network (DENet) for automatic glaucoma screening is proposed, which integrates the deep hierarchical context of the global fundus image and the local optic disc region. Four deep streams on different levels and modules are respectively considered as global image stream, segmentation-guided network, local disc region stream, and disc polar transformation stream. Finally, the output probabilities of different streams are fused as the final screening result.  
<br><br>

<strong>Reference:</strong><br>

Huazhu Fu,  Jun Cheng, Yanwu Xu, Changqing Zhang, Damon Wing Kee Wong, Jiang Liu,  Xiaochun Cao,  <strong>"Disc-aware Ensemble Network for Glaucoma Screening from Fundus Image"</strong>, 
<em>IEEE Transactions on Medical Imaging (TMI)</em>, 2018. In press. (DOI: 10.1109/TMI.2018.2837012) <br>
<a href="http://arxiv.org/abs/1805.07549" target="_blank">[PDF]</a> 
<a href="https://github.com/HzFu/DENet_GlaucomaScreen" target="_blank"><font color="#ff0000">[Code]</font></a>

<br><br>

<div style="text-align: center; display: block; margin-right: auto;">
<img src="sub_img/framework_DENet.jpg" border="0" width="600"><br></div> 
Figure: Architecture of our DENet, which contains four streams: global image stream produces the result based on the global fundus image; the segmentation guided network localizes the optic disc region and generates a detection output embedded the disc-segmentation representation; disc region stream works on disc region cropped by disc segmentation map from segmentation-guided network; disc polar stream transfers the disc region image into the polar coordinate system. The combination of these four streams is fused as the final glaucoma screening result.
<br>

<br>
<hr />



<h3>Other Related Works:</h3>

<ol>

<li>Huazhu Fu, Yanwu Xu, Stephen Lin, Damon Wing Kee Wong, Jiang Liu,  <strong>"DeepVessel: Retinal Vessel Segmentation via Deep Learning and Conditional Random Field"</strong>,  
in <em>International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI)</em>, 2016, pp. 132-139. <br>
<a href="http://dx.doi.org/10.1007/978-3-319-46723-8_16" class="user-mention" target="_blank">[PDF]</a> <a href="proj_deepvessel.html">[Project]</a></li>

<li>Huazhu Fu,  Yanwu Xu, Stephen Lin, Xiaoqin Zhang, Damon Wing Kee Wong, Jiang Liu, Alejandro F. Frangi,  Mani Baskaran, Tin Aung,  <strong>"Segmentation and Quantification for Angle-Closure Glaucoma Assessment in Anterior Segment OCT"</strong>,  
<em>IEEE Transactions on Medical Imaging (TMI)</em>, vol. 36, no. 9, pp. 1930-1938, 2017.  <br> 
<a href="https://doi.org/10.1109/TMI.2017.2703147" target="_blank">[PDF]</a> <a href="proj_glaucoma_asoct.html" target="_blank">[Project]</a></li>

</ol>

<br>


      </section>

    </div>
<script src="javascripts/scale.fix.js"></script>
  </body>
</html>


