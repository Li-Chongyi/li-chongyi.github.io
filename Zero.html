<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<!-- saved from url=(0048)https://xinntao.github.io/projects/EDVR#citation -->
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  
  <title>Zero-Reference Deep Curve Estimation for Low-Light Image Enhancement</title>
  <!--=================Meta tags==========================-->
  <meta name="robots" content="index,follow">
  <meta name="description" content="Zero-Reference Deep Curve Estimation for Low-Light Image Enhancement.">
  <meta name="keywords" content="Zero-Reference">
  <link rel="author" href="https://xinntao.github.io/projects/EDVR">
  <!--=================js==========================-->
  <link href="./EDVR_ Video Restoration with Enhanced Deformable Convolutional Networks_files/css.css" rel="stylesheet" type="text/css">
  <link rel="stylesheet" type="text/css" href="./EDVR_ Video Restoration with Enhanced Deformable Convolutional Networks_files/project.css" media="screen">
  <script type="text/javascript" async="" src="./EDVR_ Video Restoration with Enhanced Deformable Convolutional Networks_files/analytics.js.download"></script><script src="./EDVR_ Video Restoration with Enhanced Deformable Convolutional Networks_files/effect.js.download"></script>
  <!-- Latex -->
  <script type="text/x-mathjax-config;executed=true">
    MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
        TeX: { equationNumbers: { autoNumber: "AMS" } },
      });
      </script>
  <script type="text/javascript" async="" src="./EDVR_ Video Restoration with Enhanced Deformable Convolutional Networks_files/latest.js.download">
    </script>
  <!--=================Google Analytics==========================-->
  <script async="" src="./EDVR_ Video Restoration with Enhanced Deformable Convolutional Networks_files/js"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }
    gtag('js', new Date());

    gtag('config', 'UA-129775907-1');
  </script>
<script type="text/javascript" async="" src="./EDVR_ Video Restoration with Enhanced Deformable Convolutional Networks_files/MathJax.js.download"></script><style type="text/css">.MathJax_Hover_Frame {border-radius: .25em; -webkit-border-radius: .25em; -moz-border-radius: .25em; -khtml-border-radius: .25em; box-shadow: 0px 0px 15px #83A; -webkit-box-shadow: 0px 0px 15px #83A; -moz-box-shadow: 0px 0px 15px #83A; -khtml-box-shadow: 0px 0px 15px #83A; border: 1px solid #A6D ! important; display: inline-block; position: absolute}
.MathJax_Menu_Button .MathJax_Hover_Arrow {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 4px; -webkit-border-radius: 4px; -moz-border-radius: 4px; -khtml-border-radius: 4px; font-family: 'Courier New',Courier; font-size: 9px; color: #F0F0F0}
.MathJax_Menu_Button .MathJax_Hover_Arrow span {display: block; background-color: #AAA; border: 1px solid; border-radius: 3px; line-height: 0; padding: 4px}
.MathJax_Hover_Arrow:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_Hover_Arrow:hover span {background-color: #CCC!important}
</style><style type="text/css">#MathJax_About {position: fixed; left: 50%; width: auto; text-align: center; border: 3px outset; padding: 1em 2em; background-color: #DDDDDD; color: black; cursor: default; font-family: message-box; font-size: 120%; font-style: normal; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 15px; -webkit-border-radius: 15px; -moz-border-radius: 15px; -khtml-border-radius: 15px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_About.MathJax_MousePost {outline: none}
.MathJax_Menu {position: absolute; background-color: white; color: black; width: auto; padding: 2px; border: 1px solid #CCCCCC; margin: 0; cursor: default; font: menu; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
.MathJax_MenuItem {padding: 2px 2em; background: transparent}
.MathJax_MenuArrow {position: absolute; right: .5em; padding-top: .25em; color: #666666; font-size: .75em}
.MathJax_MenuActive .MathJax_MenuArrow {color: white}
.MathJax_MenuArrow.RTL {left: .5em; right: auto}
.MathJax_MenuCheck {position: absolute; left: .7em}
.MathJax_MenuCheck.RTL {right: .7em; left: auto}
.MathJax_MenuRadioCheck {position: absolute; left: 1em}
.MathJax_MenuRadioCheck.RTL {right: 1em; left: auto}
.MathJax_MenuLabel {padding: 2px 2em 4px 1.33em; font-style: italic}
.MathJax_MenuRule {border-top: 1px solid #CCCCCC; margin: 4px 1px 0px}
.MathJax_MenuDisabled {color: GrayText}
.MathJax_MenuActive {background-color: Highlight; color: HighlightText}
.MathJax_MenuDisabled:focus, .MathJax_MenuLabel:focus {background-color: #E8E8E8}
.MathJax_ContextMenu:focus {outline: none}
.MathJax_ContextMenu .MathJax_MenuItem:focus {outline: none}
#MathJax_AboutClose {top: .2em; right: .2em}
.MathJax_Menu .MathJax_MenuClose {top: -10px; left: -10px}
.MathJax_MenuClose {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; font-family: 'Courier New',Courier; font-size: 24px; color: #F0F0F0}
.MathJax_MenuClose span {display: block; background-color: #AAA; border: 1.5px solid; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; line-height: 0; padding: 8px 0 6px}
.MathJax_MenuClose:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_MenuClose:hover span {background-color: #CCC!important}
.MathJax_MenuClose:hover:focus {outline: none}
</style><style type="text/css">.MathJax_Preview .MJXf-math {color: inherit!important}
</style><style type="text/css">.MJX_Assistive_MathML {position: absolute!important; top: 0; left: 0; clip: rect(1px, 1px, 1px, 1px); padding: 1px 0 0 0!important; border: 0!important; height: 1px!important; width: 1px!important; overflow: hidden!important; display: block!important; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none}
.MJX_Assistive_MathML.MJX_Assistive_MathML_Block {width: 100%!important}
</style><style type="text/css">#MathJax_Zoom {position: absolute; background-color: #F0F0F0; overflow: auto; display: block; z-index: 301; padding: .5em; border: 1px solid black; margin: 0; font-weight: normal; font-style: normal; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; -webkit-box-sizing: content-box; -moz-box-sizing: content-box; box-sizing: content-box; box-shadow: 5px 5px 15px #AAAAAA; -webkit-box-shadow: 5px 5px 15px #AAAAAA; -moz-box-shadow: 5px 5px 15px #AAAAAA; -khtml-box-shadow: 5px 5px 15px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_ZoomOverlay {position: absolute; left: 0; top: 0; z-index: 300; display: inline-block; width: 100%; height: 100%; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
#MathJax_ZoomFrame {position: relative; display: inline-block; height: 0; width: 0}
#MathJax_ZoomEventTrap {position: absolute; left: 0; top: 0; z-index: 302; display: inline-block; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
</style><style type="text/css">.MathJax_Preview {color: #888}
#MathJax_Message {position: fixed; left: 1em; bottom: 1.5em; background-color: #dda0dd; border: 1px solid #959595; margin: 0px; padding: 2px 8px; z-index: 102; color: black; font-size: 100%; width: auto; white-space: nowrap}
#MathJax_MSIE_Frame {position: absolute; top: 0; left: 0; width: 0px; z-index: 101; border: 0px; margin: 0px; padding: 0px}
.MathJax_Error {color: #CC0000; font-style: italic}
</style><style type="text/css">.MJXp-script {font-size: .8em}
.MJXp-right {-webkit-transform-origin: right; -moz-transform-origin: right; -ms-transform-origin: right; -o-transform-origin: right; transform-origin: right}
.MJXp-bold {font-weight: bold}
.MJXp-italic {font-style: italic}
.MJXp-scr {font-family: MathJax_Script,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-frak {font-family: MathJax_Fraktur,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-sf {font-family: MathJax_SansSerif,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-cal {font-family: MathJax_Caligraphic,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-mono {font-family: MathJax_Typewriter,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-largeop {font-size: 150%}
.MJXp-largeop.MJXp-int {vertical-align: -.2em}
.MJXp-math {display: inline-block; line-height: 1.2; text-indent: 0; font-family: 'Times New Roman',Times,STIXGeneral,serif; white-space: nowrap; border-collapse: collapse}
.MJXp-display {display: block; text-align: center; margin: 1em 0}
.MJXp-math span {display: inline-block}
.MJXp-box {display: block!important; text-align: center}
.MJXp-box:after {content: " "}
.MJXp-rule {display: block!important; margin-top: .1em}
.MJXp-char {display: block!important}
.MJXp-mo {margin: 0 .15em}
.MJXp-mfrac {margin: 0 .125em; vertical-align: .25em}
.MJXp-denom {display: inline-table!important; width: 100%}
.MJXp-denom > * {display: table-row!important}
.MJXp-surd {vertical-align: top}
.MJXp-surd > * {display: block!important}
.MJXp-script-box > *  {display: table!important; height: 50%}
.MJXp-script-box > * > * {display: table-cell!important; vertical-align: top}
.MJXp-script-box > *:last-child > * {vertical-align: bottom}
.MJXp-script-box > * > * > * {display: block!important}
.MJXp-mphantom {visibility: hidden}
.MJXp-munderover, .MJXp-munder {display: inline-table!important}
.MJXp-over {display: inline-block!important; text-align: center}
.MJXp-over > * {display: block!important}
.MJXp-munderover > *, .MJXp-munder > * {display: table-row!important}
.MJXp-mtable {vertical-align: .25em; margin: 0 .125em}
.MJXp-mtable > * {display: inline-table!important; vertical-align: middle}
.MJXp-mtr {display: table-row!important}
.MJXp-mtd {display: table-cell!important; text-align: center; padding: .5em 0 0 .5em}
.MJXp-mtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-mlabeledtr {display: table-row!important}
.MJXp-mlabeledtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mlabeledtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
.MJXp-scale0 {-webkit-transform: scaleX(.0); -moz-transform: scaleX(.0); -ms-transform: scaleX(.0); -o-transform: scaleX(.0); transform: scaleX(.0)}
.MJXp-scale1 {-webkit-transform: scaleX(.1); -moz-transform: scaleX(.1); -ms-transform: scaleX(.1); -o-transform: scaleX(.1); transform: scaleX(.1)}
.MJXp-scale2 {-webkit-transform: scaleX(.2); -moz-transform: scaleX(.2); -ms-transform: scaleX(.2); -o-transform: scaleX(.2); transform: scaleX(.2)}
.MJXp-scale3 {-webkit-transform: scaleX(.3); -moz-transform: scaleX(.3); -ms-transform: scaleX(.3); -o-transform: scaleX(.3); transform: scaleX(.3)}
.MJXp-scale4 {-webkit-transform: scaleX(.4); -moz-transform: scaleX(.4); -ms-transform: scaleX(.4); -o-transform: scaleX(.4); transform: scaleX(.4)}
.MJXp-scale5 {-webkit-transform: scaleX(.5); -moz-transform: scaleX(.5); -ms-transform: scaleX(.5); -o-transform: scaleX(.5); transform: scaleX(.5)}
.MJXp-scale6 {-webkit-transform: scaleX(.6); -moz-transform: scaleX(.6); -ms-transform: scaleX(.6); -o-transform: scaleX(.6); transform: scaleX(.6)}
.MJXp-scale7 {-webkit-transform: scaleX(.7); -moz-transform: scaleX(.7); -ms-transform: scaleX(.7); -o-transform: scaleX(.7); transform: scaleX(.7)}
.MJXp-scale8 {-webkit-transform: scaleX(.8); -moz-transform: scaleX(.8); -ms-transform: scaleX(.8); -o-transform: scaleX(.8); transform: scaleX(.8)}
.MJXp-scale9 {-webkit-transform: scaleX(.9); -moz-transform: scaleX(.9); -ms-transform: scaleX(.9); -o-transform: scaleX(.9); transform: scaleX(.9)}
.MathJax_PHTML .noError {vertical-align: ; font-size: 90%; text-align: left; color: black; padding: 1px 3px; border: 1px solid}
</style></head>

<body><div id="MathJax_Message" style="display: none;"></div>
  <div id="content">
    <div id="content-inner">
      <div class="section head">
        <h1>
          <font color="LightSkyBlue">Zero</font>-Reference <font color="LightSkyBlue">D</font>eep <font color="LightSkyBlue">C</font>urve <font color="LightSkyBlue">E</font>stimation (<font color="LightSkyBlue">Zero-DCE</font>)
        </h1>
        <h1>for Low-Light Image Enhancement</h1>
        <!--=================Authors==========================-->
        <div class="authors">
          Chunle Guo <sup>1</sup> &nbsp;&nbsp;&nbsp;&nbsp;
          <a href="https://li-chongyi.github.io/" target="_blank">Chongyi Li</a> <sup>2</sup> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
          Jichang Guo <sup>1</sup> &nbsp;&nbsp;&nbsp;&nbsp;
          <a href="http://personal.ie.cuhk.edu.hk/~ccloy/index.html" target="_blank">Chen Change Loy</a> <sup>3</sup>&nbsp;&nbsp;&nbsp;&nbsp;
          <a href="https://sites.google.com/site/junhuihoushomepage/" target="_blank">Junhui Hou</a> <sup>2</sup>&nbsp;&nbsp;&nbsp;&nbsp;
          <a href="https://www.cs.cityu.edu.hk/~cssamk/research_group/index.html" target="_blank">Sam Kwong</a> <sup>2</sup>&nbsp;&nbsp;&nbsp;&nbsp;
          <a href="https://rmcong.github.io/" target="_blank">Runmin Cong</a> <sup>4</sup>
        </div>

        <div class="affiliations ">
          <sup>1</sup> Tianjin University, Tianjin, China <br>
          <sup>2</sup> City University of Hong Kong, Hong Kong<br>
          <sup>3</sup> Nanyang Technological University, Singapore<br>
          <sup>4</sup> Beijing Jiaotong University, Beijing, China
        </div>
        <!--=================Tabs==========================-->
        <ul id="tabs">
          <li><a href="https://li-chongyi.github.io/Zero.html#materials" name="#tab1">Materials</a></li>
          <li><a href="https://li-chongyi.github.io/Zero.html#pcd_tsa" name="#tab2">PCD &amp; TSA</a></li>
          <li><a href="https://li-chongyi.github.io/Zero.html#ablations" name="#tab3">Ablations</a></li>
          <li><a href="https://li-chongyi.github.io/Zero.html#results" name="#tab4">Results</a></li>
          <li><a href="https://li-chongyi.github.io/Zero.html#citation" name="#tab5">Citation</a></li>
      </ul></div>
      <br>
      <!--=================Teasers==========================-->
      <div id="img_intro_examples" class="img_container">
        <center>
          <div class="leftView">
            <div class="mask" style="width:80px;height:80px"></div>
            <img class="small" src="./EDVR_ Video Restoration with Enhanced Deformable Convolutional Networks_files/arch.png">
          </div>
        </center>
      </div>
      <div class="section">
        <p><b>The EDVR framework</b>. It is a unified framework suitable for various video restoration tasks,
          <i>e.g.</i>, super-resolution and
          deblurring. Inputs with high spatial resolution are first down-sampled to reduce computational cost. Given
          blurry inputs, a PreDeblur
          Module is inserted before the PCD Align Module to improve alignment accuracy. We use three input frames as an
          illustrative example.</p>
      </div>
      <!--=================Highlights==========================-->
      <div class="section abstract">
        <h2>Highlights</h2>
        <ol>
          <li>EDVR wins all <b>four</b> tracks in the <a href="http://www.vision.ee.ethz.ch/ntire19/" target="_blank">NTIRE19 video restoration and enhancement challenges</a>.</li>
          <li>We propose the PCD alignment module and TSA fusion module for effective alignment and fusion, respectively.
          </li>
          <li>We are constructing the <a href="https://xinntao.github.io/open-videorestoration/" target="_blank"><b>Open Video Restoration</b></a> project.
          </li>
        </ol>
      </div>
      <!--=================Materials==========================-->
      <div class="section materials" ,="" id="materials">
        <h2>Materials</h2>
        <table width="100%" align="center" border="none" cellspacing="0" cellpadding="30">
          <tbody><tr>
            <td width="40%">
              <center>
                <a href="https://arxiv.org/abs/1905.02716" target="_blank" class="imageLink"><img src="./EDVR_ Video Restoration with Enhanced Deformable Convolutional Networks_files/paper_thumbnail.jpg" ,="" width="80%"></a><br><br>
                <a href="https://arxiv.org/abs/1905.02716" target="_blank">Paper</a>
              </center>
            </td>
            <td width="20%" valign="middle">
              <center>
                <a href="https://github.com/xinntao/EDVR" target="_blank" class="imageLink"><img src="./EDVR_ Video Restoration with Enhanced Deformable Convolutional Networks_files/icon_github.png" ,="" width="50%"></a><br><br>
                <a href="https://github.com/xinntao/EDVR" target="_blank">Codes</a>
              </center>
            </td>
            <td width="40%" valign="middle">
              <center>
                <a href="https://xinntao.github.io/open-videorestoration/" target="_blank" class="imageLink"><img src="./EDVR_ Video Restoration with Enhanced Deformable Convolutional Networks_files/open_video.png" ,="" width="50%"></a><br><br>
                <a href="https://xinntao.github.io/open-videorestoration/" target="_blank">Open Video Restoration</a>
              </center>
            </td>
          </tr>
        </tbody></table>
      </div>

      <!--=================Abstract==========================-->
      <div class="section abstract">
        <h2>Abstract</h2>
        <br>
        <p>
          Video restoration tasks, including super-resolution, deblurring, <i>etc</i>, are drawing increasing attention
          in the computer
          vision community. A challenging benchmark named REDS is released in the NTIRE19 Challenge. This new benchmark
          challenges
          existing methods from two aspects: (1) how to <b>align</b> multiple frames given large motions, and (2) how to
          effectively <b>fuse</b>
          different frames with diverse motion and blur. In this work, we propose a novel Video Restoration framework
          with
          Enhanced Deformable networks, termed EDVR, to address these challenges. First, to handle large motions, we
          devise a
          <b>Pyramid, Cascading and Deformable (PCD) alignment module</b>, in which frame alignment is done at the
          feature level using
          deformable convolutions in a coarse-to-fine manner. Second, we propose a <b>Temporal and Spatial Attention
            (TSA) fusion
            module</b>, in which attention is applied both temporally and spatially, so as to emphasize important
          features for
          subsequent restoration. Thanks to these modules, our EDVR <b><i>wins the champions</i></b> and outperforms the
          second place by <b><i>a large
              margin</i></b> in all four tracks in the NTIRE19 video restoration and enhancement challenges. EDVR also
          demonstrates superior
          performance to state-of-the-art published methods on video super-resolution and deblurring.
        </p>
      </div>
      <!--=================PCD and TSA Modules==========================-->
      <div class="section" ,="" id="pcd_tsa">
        <h2> PCD and TSA Modules</h2>
        <p>
          <b>Left:</b> PCD alignment module with Pyramid, Cascading and Deformable convolution; <b>Right:</b> TSA
          fusion module with Temporal and Spatial Attention. See <a href="https://xinntao.github.io/projects/EDVR#">our paper</a> for more details.
        </p>
        <div id="sr" class="img_container">
          <center>
            <img style="width:80%" src="./EDVR_ Video Restoration with Enhanced Deformable Convolutional Networks_files/pcd_tsa.jpg">
          </center>
        </div>
      </div>
      <br>

      <!--=================Ablation studies==========================-->
      <div class="section" ,="" id="ablations">
        <h2>Ablation Studies on PCD and TSA Modules</h2>
        <p>
          We show representative features before and after different alignment modules, and depict the flow (derived by
          PWCNet)
          between reference and neighboring features. Compared with the flow without PCD alignment, the flow of the PCD
          outputs
          is much smaller and cleaner, indicating that the PCD module can successfully handle large and complex motions.
        </p>
        <div id="sr" class="img_container">
          <center>
            <img style="width:90%" src="./EDVR_ Video Restoration with Enhanced Deformable Convolutional Networks_files/pcd_flow.jpg">
          </center>
        </div>
        <p>
          We present the flow between the reference and neighboring frames, together with the temporal attention of each
          frame.
          It is observed that the frames and regions with lower flow magnitude tend to have higher attention, indicating
          that
          the smaller the motion is, the more informative
          the corresponding frames and regions are.
        </p>
        <div id="sr" class="img_container">
          <center>
            <img style="width:90%" src="./EDVR_ Video Restoration with Enhanced Deformable Convolutional Networks_files/tsa_flow.jpg">
          </center>
        </div>
      </div>
      <br>
      <!--=================Applications==========================-->
      <div class="section" ,="" id="results">
        <h2>Results</h2>
        <!--=================*******==========================-->
        <h3>1. Video Super-Resolution on Vid4 Dataset</h3>
        <div id="vid4" class="img_container">
          <center>
            <div class="leftView">
              <div class="mask" style="width:70px;height:70px"></div>
              <img class="small" src="./EDVR_ Video Restoration with Enhanced Deformable Convolutional Networks_files/vid4.jpg">
            </div>
          </center>
        </div>
        <br>
        <!--=================*******==========================-->
        <h3>2. Video Super-Resolution on Vimeo90K Dataset</h3>
        <div id="vimeo90k" class="img_container">
          <center>
            <div class="leftView">
              <div class="mask" style="width:70px;height:70px"></div>
              <img class="small" src="./EDVR_ Video Restoration with Enhanced Deformable Convolutional Networks_files/vimeo90k.jpg">
            </div>
          </center>
        </div>
        <br>
        <!--=================*******==========================-->
        <h3>3. Video Deblurring on REDS4 Dataset</h3>
        <div id="reds4" class="img_container">
          <center>
            <div class="leftView">
              <div class="mask" style="width:70px;height:70px"></div>
              <img class="small" src="./EDVR_ Video Restoration with Enhanced Deformable Convolutional Networks_files/reds_deblur.jpg">
            </div>
          </center>
        </div>
        <br>
        <!--=================*******==========================-->
        <h3>4. Competition Results on REDS4 Dataset</h3>
        <div id="reds4" class="img_container">
          <center>
            <div class="leftView">
              <div class="mask" style="width:70px;height:70px"></div>
              <img class="small" src="./EDVR_ Video Restoration with Enhanced Deformable Convolutional Networks_files/reds.jpg">
            </div>
          </center>
        </div>
        <br>
      </div>
      <!--=================Citation==========================-->
      <div class="section citation" ,="" id="citation">
        <h2>Citation</h2>
        <div class="section bibtex">
          <pre>@InProceedings{wang2019edvr,
          author = {Wang, Xintao and Chan, Kelvin C.K. and Yu, Ke and Dong, Chao and Loy, Chen Change},
          title = {EDVR: Video Restoration with Enhanced Deformable Convolutional Networks},
          booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
          month = {June},
          year = {2019}
          }
          </pre>
          <pre>@Article{tian2018tdan,
          author = {Tian, Yapeng and Zhang, Yulun and Fu, Yun and Xu, Chenliang},
          title = {TDAN: Temporally deformable alignment network for video super-resolution},
          journal = {arXiv preprint arXiv:1812.02898},
          year = {2018}
          }
          </pre>
        </div>
      </div>
      <!--=================Contact==========================-->
      <div class="section contact">
        <h2 id="contact">Contact</h2>
        <p>If you have any question, please contact Xintao Wang at <strong>wx016@ie.cuhk.edu.hk</strong>.</p>
      </div>


</div></div></body></html>
