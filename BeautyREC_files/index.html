<!DOCTYPE html
  PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>BeautyREC: Robust, Efficient, and Component-Specific Makeup Transfer</title>
  <!--=================Meta tags==========================-->
  <meta name="robots" content="index,follow">
  <meta name="keywords" content="curve, tangent line, exposure correction">
  <link rel="author" href="https://li-chongyi.github.io//">
  <!--=================js==========================-->
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  <link href="./css.css" rel="stylesheet" type="text/css">
  <link rel="stylesheet" type="text/css" href="./project.css" media="screen">
  <script src="./effect.js "></script>
  <!-- Latex -->
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
        TeX: { equationNumbers: { autoNumber: "AMS" } },
      });
      </script>
  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML">
    </script>
  <script type="text/javascript" async src="./canvas-nest-1.0.1.min.js"></script>

  <!--=================Google Analytics==========================-->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-129775907-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }
    gtag('js', new Date());

    gtag('config', 'UA-129775907-1');
  </script>
</head>

<body>
  <div id="content">
    <div id="content-inner">
      <div class="section head">
        <br> 
        <h1>
          <font color="#FF0000">BeautyREC</font>: 
          <font color="#FF0000">R</font>obust, 
          <font color="#FF0000">E</font>fficient, and 
          <font color="#FF0000">C</font>omponent-Specific,  <br>Makeup Transfer
        </h1>
       <!--  <h1>
        </h1> -->
        <!--=================Authors==========================-->
        <div class="authors">
          <br>
          <a href="https://scholar.google.com/citations?hl=en&user=-3ZVCV0AAAAJ" target="_blank">Qixin Yan</a> 
          &nbsp;&nbsp;&nbsp;&nbsp;
          &nbsp;&nbsp;&nbsp;&nbsp;
          <a href="https://scholar.google.com.au/citations?user=RZLYwR0AAAAJ&hl=en" target="_blank">Chunle Guo</a> 
          &nbsp;&nbsp;&nbsp;&nbsp;
          &nbsp;&nbsp;&nbsp;&nbsp;
          <a href="" target="_blank">Jixin Zhao</a> 
          &nbsp;&nbsp;&nbsp;&nbsp;
          &nbsp;&nbsp;&nbsp;&nbsp;
          <a href="https://scholar.google.com/citations?user=UyKX7ZsAAAAJ&hl=en&inst=10972715779114120479&oi=ao" target="_blank">Yuekun Dai</a> 
          &nbsp;&nbsp;&nbsp;&nbsp;
          &nbsp;&nbsp;&nbsp;&nbsp;
          <a href="https://www.mmlab-ntu.com/person/ccloy/" target="_blank">Chen Change Loy</a>
          &nbsp;&nbsp;&nbsp;&nbsp;
          &nbsp;&nbsp;&nbsp;&nbsp;
          <a href="https://li-chongyi.github.io/" target="_blank">Chongyi Li<sup>*</sup></a> 
        </div>

        <div class="affiliations ">
          WeChat, Tencent, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;   TMCC, Nankai University,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  S-Lab, Nanyang Technological University<br>
        </div>
        <!--=================Tabs==========================-->
        <ul id="tabs">
          <li><a href="#abstract" name="#tab1">Abstract</a></li>
          <li><a href="#method" name="#tab3">Method</a></li>
          <li><a href="#dataset" name="#tab4">Dataset</a></li>
          <li><a href="#citation" name="#tab5">Citation</a></li>
      </div>
      <br>
      <!--=================Teasers==========================-->
      <div class="section" , id="method">
        <h2></h2>
        <div style="text-align: center; vertical-align:middle">
          <img src="src/Teasers.png" width="900">
        </div>
        <div align="center" style="margin-top: 5px">
          <b>Results achieved by our method with a single model.</b>
        </div>
      </div>



      <!--=================Abstract==========================-->
      <div class="section abstract", id="abstract">
        <h2>Abstract</h2>
        <p style="text-align:justify; text-justify:inter-ideograph;"> 
          <br>


In this work, we propose a <strong>R</strong>obust, <strong>E</strong>fficient, and <strong>C</strong>omponent-specific makeup transfer method (abbreviated as <strong>BeautyREC</strong>). A unique departure from prior methods that leverage global attention, simply concatenate features, or implicitly manipulate features in latent space,  we propose a component-specific correspondence to directly transfer the makeup style of a reference image to the corresponding components (e.g., skin, lips, eyes) of a source image, making elaborate and accurate local makeup transfer. As an auxiliary, the long-range visual dependencies of Transformer are introduced for effective global makeup transfer. Instead of the commonly used cycle structure that is complex and unstable,  we employ a content consistency loss coupled with a content encoder to implement efficient single-path makeup transfer. The key insights of this study are modeling component-specific correspondence for local makeup transfer,   capturing long-range dependencies for global makeup transfer, and enabling efficient makeup transfer via a single-path structure. 

We also contribute \textbf{BeautyFace}, a makeup transfer dataset to supplement existing datasets.  This dataset contains 3,000 faces, covering more diverse makeup styles, face poses, and races. Each face has annotated parsing map. Extensive experiments demonstrate the effectiveness of our method against state-of-the-art methods. Besides, our method is appealing as it is with only 1M parameters, outperforming the state-of-the-art methods (BeautyGAN: 8.43M,  PSGAN: 12.62M, SCGAN: 15.30M, CPM: 9.24M, SSAT: 10.48M).

        </p>
      </div>

      <!--=================Method==========================-->
      <div class="section" , id="method">
        <h2>Method</h2>
        <div style="text-align: center; vertical-align:middle">
          <img src="src/framework.png" width="700">
        </div>
        <div align="center" style="margin-top: 5px">
          <b>Framework Overview.</b>
        </div>
        <p style="text-align:justify; text-justify:inter-ideograph;"> 
          It consists of a content encoder, a component style encoder, a global style encoder, a component-specific correspondence, a long-range dependency, and an image reconstruction. Note that the skip-connections between the content encoder and image reconstruction are removed in figure for brevity.
        </p>
      </div>

            <!--=================Dataset==========================-->
      <div class="section" , id="dataset">
        <h2>Dataset</h2>
         <div style="text-align: center; vertical-align:middle">
          <img src="src/dataset.png" width="700">
        </div>
        <div align="center" style="margin-top: 5px">
          <b>Dataset Overview.</b>
        </div>
        <p style="text-align:justify; text-justify:inter-ideograph;"> 
          It contains 3,000 high-quality face images with a higher resolution of 512*512, covering more recent makeup styles and more diverse face poses, backgrounds, expressions, races, illumination, etc. Besides, we annotate each face with parsing, which benefits more diverse applications. 
        </p>
      </div>

            <!--=================Demo==========================-->
      <div class="section demo">
        <br>
        <center> <video  muted="muted" width="740" class="publogo"   controls= "autoPlay" onended="this.currentTime = 0; this.play();" autoplay="" src="src/BeautyREC_video.mp4"> <source src="src/CuDi.mp4" type="video/mp4"></video>
        </center>
        <br>
        <p align="center" style="margin-top: -2px">
        <b>Video Demo</b><br>
        <b><font color="#FF0000">The results are achieved by our BeautyREC with only 1M parameters.</font></b>
        </p>

             <!--=================Materials==========================-->
      <div class="section materials" , id="materials">
        <h2>Materials</h2>
        <br>
        <table width="100%" align="center" border=none cellspacing="0" cellpadding="30">
          <tr>
            <td width="50%">
              <center>
                <a href="https://arxiv.org/abs/2212.05855" target="_blank" class="imageLink"><img
                    src="./src/thumbnail.png" , height="120"></a><br><br>
                <a href="https://arxiv.org/abs/2212.05855" disabled target="_blank">Paper</a>
              </center>
            </td>
            <td width="30%" valign="middle">
              <center>
                <a href="https://li-chongyi.github.io/BeautyREC_files/" target="_blank" class="imageLink"><img
                    src="./src/icon_github.png" , height="120"></a><br><br>
                <a href="https://github.com/learningyan/BeautyREC/" target="_blank">Code+Dataset</a>
              </center>
            </td>
          </tr>
        </table>
      </div>



      <!--=================Citation==========================-->
      <div class="section citation" , id="citation">
        <h2>Citation</h2>
        <p>If you find our dataset and paper useful for your research, please consider citing our work:
        </p>
        <div class="section bibtex">
          <pre>@inproceedings{BeautyREC,
          author = {Yan, Qixin and Guo, Chunle and Zhao, Jixin and Dai, Yuekun and Loy, Chen Change and Li, Chongyi},
          title = {BeautyREC: Robust, Efficient, and Component-Specific Makeup Transfer},
          booktitle = {Arixv},
          year = {2022}
          }</pre>
        </div>
      </div>

      <!--=================License==========================-->
      <div class="section" , id="License">
        <h2>License</h2>
        <p>
          We retain all the copyrights of this method.
        </p>
      </div> 


      <!--=================Contact==========================-->
      <div class="section contact">
        <h2 id="contact">Contact</h2>
        <p>If you have any question, please contact us via <strong>qixinyan@tencent.com</strong> or <strong>lichongyi25@gmail.com</strong>.
        </p>
        <br>
      </div>
</body>

</html>
