<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Video Co-segmentation</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <meta name="viewport" content="width=device-width">
  </head>
  <body>
    <div class="wrapper">
<header>
<h1>付华柱</h1>
<h1>Huazhu Fu</h1>

<p>
<small>huazhufu (AT) gmail (DOT) com </small><br><br>
<a href="https://github.com/HzFu" target="_blank">[GitHub]</a>  
<a href="http://dblp.uni-trier.de/pers/hd/f/Fu:Huazhu" target="_blank">[DBLP]</a>  <br>
<a href="http://scholar.google.com.sg/citations?user=jCvUBYMAAAAJ" target="_blank">[Google Scholar]</a> </p> <br>
<p class="view"><a href="http://hzfu.github.io/">Homepage</a></p>
<p class="view"><a href="sub_publication.html">Publications</a></p>
<p class="view"><a href="sub_projects.html">Projects</a></p>
</header>

      <section>

<h2>
<a id="project_title" class="anchor" href="#project_title" aria-hidden="true"><span class="octicon octicon-link"></span></a>Object-based Video Co-segmentation</h2>

<hr/>

<div style="text-align: center; display: block; margin-right: auto;">
<img src="sub_img/video_coseg_framework.jpg" border="0" width="600"><br></div><br>

<h4>
<a id="Introduction-page" class="anchor" href="#Introduction-pages" aria-hidden="true"><span class="octicon octicon-link"></span></a>Introduction:</h4>

<p>We present a video co-segmentation method that uses category-independent object proposals as its basic element and can extract multiple foreground objects in a video set. The use of object elements overcomes limitations of low-level feature representations in separating complex foregrounds and backgrounds. We formulate object-based co-segmentation as a co-selection graph in which regions with foreground-like characteristics are favored while also accounting for intra-video and inter-video foreground coherence. To handle multiple foreground objects, we expand the co-selection graph model into a proposed multi-state selection graph model (MSG) that optimizes the segmentations of different objects jointly. This extension into the MSG can be applied not only to our co-selection graph, but also can be used to turn any standard graph model into a multi-state selection solution that can be optimized directly by the existing energy minimization techniques. Our experiments show that our object-based multiple foreground video co-segmentation method (ObMiC) compares well to related techniques on both single and multiple foreground cases.</p>

<hr/>

<h4> Performances: </h4>

<p> There are two datasets used in our paper: MOViCS dataset and our Video Coseg dataset. </p>
<table>
1. CVPR/TIP on Video Coseg dataset:
  <tr>
  <th> </th>
    <th>Dog</th>
    <th>Person</th>
    <th>Monster</th>
    <th>Skating</th>
    <th>Avg.</th>
  </tr>
  <tr>
    <td>Acc</td>
    <td>1115</td>
    <td>9321</td>
    <td>3551</td>
    <td>3274</td>
    <td>4315</td>
  </tr>
  <tr>
    <td>IOU</td>
    <td>0.753</td>
    <td>0.542</td>
    <td>0.795</td>
    <td>0.666</td>
    <td>0.689</td>
  </tr>
</table>

<table>
2. CVPR on MOViCS dataset (single object):
  <tr>
  <th> </th>
    <th>Chicken</th>
    <th>Giraffe</th>
    <th>Lion</th>
    <th>Tiger</th>
    <th>Avg.</th>
  </tr>
  <tr>
    <td>Acc</td>
    <td>1567</td>
    <td>2938</td>
    <td>1598</td>
    <td>21005</td>
    <td>6726</td>
  </tr>
  <tr>
    <td>IOU</td>
    <td>0.872</td>
    <td>0.668</td>
    <td>0.828</td>
    <td>0.714</td>
    <td>0.771</td>
  </tr>
</table>

<table>
3. TIP on MOViCS dataset (multi-object):
  <tr>
  <th> </th>
    <th>Chicken/Turtle</th>
    <th>Giraffe/Elephant</th>
    <th>Lion/Zebra</th>
    <th>Tiger</th>
    <th>Avg.</th>
  </tr>
  <tr>
    <td>Acc</td>
    <td>2372</td>
    <td>3396</td>
    <td>6084</td>
    <td>21005</td>
    <td>8214</td>
  </tr>
  <tr>
    <td>IOU</td>
    <td>0.879</td>
    <td>0.553</td>
    <td>0.616</td>
    <td>0.714</td>
    <td>0.691</td>
  </tr>
</table>

<hr/>

<h4>Paper:</h4>
    
<p>[1] <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2014/html/Fu_Object-based_Multiple_Foreground_2014_CVPR_paper.html" target="_blank"><strong>"Object-based Multiple Foreground Video Co-segmentation"</strong></a><br>
Huazhu Fu, Dong Xu, Bao Zhang, Stephen Lin, <br>
in <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2014, pp. 3166-3173. <br>
</p>

<p>[2] <a href="http://dx.doi.org/10.1109/TIP.2015.2442915" target="_blank"><strong>"Object-based Multiple Foreground Video Co-segmentation via Multi-state Selection Graph"</strong></a><br> 
Huazhu Fu, Dong Xu, Bao Zhang, Stephen Lin, Rabab K. Ward,<br>
<em>IEEE Transactions on Image Processing (TIP)</em>, vol. 24, no. 11, pp. 3415-3424, 2015. <br>
</p>

<hr/>



<h4>Dataset and Code:</h4>
<p> 
The code can be found from here: <a href="https://github.com/HzFu/VideoCoSeg_MSG" target="_blank"><font color="#ff0000">[Code]</font></a> <br>
Our Dataset and Groundtruth (~5MB) has 8 videos (2 video in each group) including 2 objects in each video. <a href="https://onedrive.live.com/redir?resid=F3A8A31ABFAC51B0!254&authkey=!AAWcqeBYcT6Xo6c&ithint=file%2czip" target="_blank"><font color="#ff0000">[Download Link]</font></a> <a href="https://pan.baidu.com/s/1c2eocHM" target="_blank"><font color="#ff0000">[BaiduYun]</font></a><br>
Other related video co-segmentation dataset: MOViCS (CVPR13) <a href="https://sites.google.com/site/walonchiu/projects/cosegmentation" target="_blank"><font color="#ff0000">[Project Link]</font></a>.
</p>

<hr/>

<h4>Related Works:</h4>

<p>[1] Huazhu Fu, Xiaochun Cao, Zhuowen Tu, <strong>"Cluster-based Co-saliency Detection"</strong>, <em>IEEE Transactions on Image Processing (TIP)</em>, vol. 22, no. 10, pp. 3766-3778, 2013. 
<a href="http://dx.doi.org/10.1109%2FTIP.2013.2260166" target="_blank">[PDF]</a> <a href="https://github.com/HzFu/Cosaliency_tip2013" target="_blank">[Code]</a><br>

[2] Xiaochun Cao, Zhiqiang Tao, Bao Zhang, Huazhu Fu, Wei Feng, <strong>"Self-adaptively Weighted Co-saliency Detection via Rank Constraint"</strong>, <em>IEEE Transactions on Image Processing (TIP)</em>, vol. 23, no. 9, pp. 4175-4186, 2014. 
<a href="http://dx.doi.org/10.1109/TIP.2014.2332399" target="_blank"> [PDF]</a> <a href="https://github.com/HzFu/SACS_TIP2014" target="_blank">[Code]</a><br>

[3] Huazhu Fu, Dong Xu, Stephen Lin, Jiang Liu, <strong>"Object-based RGBD Image Co-segmentation with Mutex Constraint"</strong>, in <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2015, pp. 4428-4436.
<a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Fu_Object-Based_RGBD_Image_2015_CVPR_paper.html" target="_blank">[PDF]</a> <a href="proj_rgbdseg.html">[Project]</a></p>

      </section>

    </div>
    <script src="../../javascripts/scale.fix.js"></script>
  </body>
</html>
