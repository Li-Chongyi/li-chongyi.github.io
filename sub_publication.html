<!doctype html>
<html>
<head>
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="chrome=1">
<title>Publications</title>

<link rel="stylesheet" href="stylesheets/styles.css">
<link rel="stylesheet" href="stylesheets/pygment_trac.css">
<meta name="viewport" content="width=device-width">
</head>
<body>
<div class="wrapper">
<header>
<h7>Chongyi Li</h7><br><br>
<div>
<img src="sub_img/lichongyi.jpg" border="0" width="80%"><br></div><br>

  
<p>
<small>lichongyi25@gmail.com lichongyi@tju.edu.cn</small><br><br>
<a href="https://github.com/Li-Chongyi" target="_blank">[GitHub]</a>  
<a href="http://dblp.uni-trier.de/pers/hd/l/Li:Chongyi" target="_blank">[DBLP]</a>  <br>
<a href="https://scholar.google.com/citations?user=1_I0P-AAAAAJ&hl=zh-CN" target="_blank">[Google Scholar]</a> <br>
</p> <br>
<p class="view"><a href="https://li-chongyi.github.io/">Homepage</a></p>
<p class="view"><a href="sub_publication.html">Publications</a></p>
<p class="view"><a href="sub_projects.html">Projects</a></p>
</header>

<section>

<h2>
<a id="publications-pages" class="anchor" href="#publications-pages" aria-hidden="true"><span class="octicon octicon-link"></span></a>Publications:</h2>
<div style="text-align: justify; display: block; margin-right: auto;">
<!--
<h4>
<a id="publications-J-pages" class="anchor" href="#publications-J-pages" aria-hidden="true"><span class="octicon octicon-link"></span></a>Under Review</h4>

<ol>

<li> Saeed Anwar <strong>Chongyi Li</strong>, Fatih Porikli, Deep underwater image enhancement, in <strong><ud2>arXiv: 1807.03528</ud2></strong>, 2018.  <a href="https://arxiv.org/pdf/1807.03528.pdf" target="_blank"><font color="#1C86EE">[PDF]</font></a> </li>
<li> <strong>Chongyi Li</strong>, Jichang Guo, Fatih porikli, et al., DR-Net: Transmission steered single image dehazing network with weakly supervised refinement,  in <strong><ud2>arXiv: 1712.00621</ud2> </strong>, 2017. <a href="https://arxiv.org/abs/1712.00621" target="_blank"><font color="#1C86EE">[PDF]</font></a> </li>  

<li> <strong>Chongyi Li</strong>, Saeed Anwar, Junhui Hou, et al., Underwater image enhancement via depth attention-guided multi-color space embedding, <strong><ud2> IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</ud2></strong>  </li>   
<li> Wenqi Ren <strong>Chongyi Li</strong>, Lin Ma, et al., Multi-scale gated fusion network for single image dehazing and beyond, <strong><ud2> IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</ud2></strong> (co-first author) </li>
<li> Chunle Guo, <strong>Chongyi Li</strong>, Jichang Guo, et al., Zero-reference deep curve estimation for low-light image enhancement, <strong><ud2> Top Conference</ud2></strong>  (co-first author) </li>   
<li> Runmin Cong, <strong>Chongyi Li</strong>, et al., Multi-Modality Soft-to-Hard Attention Network for RGB-D Saliency Detection, <strong><ud2> Top Conference</ud2></strong>  (co-first and corresponding author) </li>   
<li> <strong>Chongyi Li</strong>, Runmin Cong, Chunle Guo, et al., A Parallel Down-Up Fusion Network for Salient Object Detection in Optical Remote Sensing Images, <strong><ud2>Neurocomputing</ud2></strong>  </li>   
<li> Saeed Anwar and <strong>Chongyi Li</strong>, Diving Deeper into Underwater Image Enhancement: A Survey, <strong><ud2> IJCV</ud2></strong> <a href="https://arxiv.org/pdf/1907.07863.pdf" target="_blank"><font color="#1C86EE">[PDF]</font></a> (co-first author) </li>
<li> Miao Yang, Hu Ke, <strong>Chongyi Li</strong>, et al., UW-Net: An inception-attention network for underwater image classification, <strong><ud2> IEEE Transactions on Image Processing (TIP)</ud2></strong>  </li>   
<li> Hua Li, Runmin Cong, <strong>Chongyi Li</strong>, et al., Stereo Superpixel: An Iterative Framework based on Parallax Consistency and Collaborative Optimization, <strong><ud2> Top Conference</ud2></strong> </li>   

</ol>   
  -->  
<h4>
<a id="publications-J-pages" class="anchor" href="#publications-J-pages" aria-hidden="true"><span class="octicon octicon-link"></span></a>2020:</h4>

<ol>
<li> <strong>Chongyi Li</strong>, Runmin Cong, Yongri Piao, et al., RGB-D salient object detection with cross-modality modulation and selection, <strong><ud2>European Conference on Computer Vision (ECCV) </ud2></strong>, 2020. <a href="" target="_blank"><font color="#1C86EE">[PDF-Arxiv version]</font></a> <a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123530222.pdf" target="_blank"><font color="#1C86EE">[PDF-offical version]</font></a> <a href="https://li-chongyi.github.io/Proj_ECCV20" target="_blank"><font color="#1C86EE">[Project]</font></a></li> 
<li> Chunle Guo, <strong>Chongyi Li (co-first author)</strong>, Jichang Guo, et al., Zero-reference deep curve estimation for low-light image enhancement, <strong><ud2>IEEE Conference on Computer Vision and Pattern Recognition (CVPR) </ud2></strong>, 2020. <a href="https://arxiv.org/abs/2001.06826" target="_blank"><font color="#1C86EE">[PDF-Arxiv version]</font></a> <a href="http://openaccess.thecvf.com/content_CVPR_2020/papers/Guo_Zero-Reference_Deep_Curve_Estimation_for_Low-Light_Image_Enhancement_CVPR_2020_paper.pdf" target="_blank"><font color="#1C86EE">[PDF-offical version]</font></a> <a href="https://li-chongyi.github.io/Proj_Zero-DCE.html" target="_blank"><font color="#1C86EE">[Project]</font></a></li> 
<li> <strong>Chongyi Li</strong>, Huazhu Fu, Runmin Cong, et al., NuI-Go: Recursive non-local encoder-decoder network for retinal image non-uniform illumination removal, <strong><ud2>ACM Multimedia (ACM MM) </ud2></strong>, 2020. <a href="https://arxiv.org/abs/2008.02984" target="_blank"><font color="#1C86EE">[PDF-Arxiv version]</font></a> <a href="" target="_blank"><font color="#1C86EE">[PDF-offical version]</font></a> <a href="https://li-chongyi.github.io/Proj_ACMMM20_NuI-Go" target="_blank"><font color="#1C86EE">[Project]</font></a></li> 
<li> Qijian Zhang, Runmin Cong, Junhui Hou, <strong>Chongyi Li</strong>, and Yao Zhao, CoADNet: Collaborative Aggregation-and-Distribution Networks for Co-Salient Object Detection,<strong><ud2>Neural Information Processing Systems (NeurIPS) </ud2></strong>, 2020. <a href="" target="_blank"><font color="#1C86EE">[PDF-Arxiv version]</font></a> <a href="" target="_blank"><font color="#1C86EE">[PDF-offical version]</font></a> <a href="" target="_blank"><font color="#1C86EE">[Project]</font></a></li> 
<li> <strong>Chongyi Li</strong>, Runmin Cong, Sam Kwong, et al., ASIF-Net: Attention steered interweave fusion network for RGB-D salient object detection, <strong><ud2>IEEE Transactions on Cybernetics </ud2></strong> (SCI, IF=10.387), 2020. <a href="https://ieeexplore.ieee.org/document/8998588" target="_blank"><font color="#1C86EE">[PDF-offical version]</font></a> <a href="https://github.com/Li-Chongyi/ASIF-Net" target="_blank"><font color="#1C86EE">[Results+Codes]</font></a></li>
<li> <strong>Chongyi Li</strong>, Runmin Cong, Chunle Guo, et al., A parallel down-up fusion network for salient object detection in optical remote sensing images, <strong><ud2>Neurocomputing</ud2></strong> (SCI, IF=4.072), 2020. <a href="" target="_blank"><font color="#1C86EE">[PDF-offical version]</font></a> <a href="" target="_blank"><font color="#1C86EE">[Results]</font></a></li>
<li> Saeed Anwar, <strong>Chongyi Li (corresponding author)</strong>, Diving deeper into underwater image enhancement: A survey, <strong><ud2>Signal Processing: Image Communication</ud2></strong> (SCI, IF=2.814), 2020. <a href="https://arxiv.org/pdf/1907.07863.pdf" target="_blank"><font color="#1C86EE">[PDF-Arxiv version]</font></a> <a href="" target="_blank"><font color="#1C86EE">[PDF-offical version]</font></a></li>  
<li> Qing Qi, Jichang Guo, <strong>Chongyi Li</strong>, and Lijun Xiao, Blind face images deblurring with enhancement, <strong><ud2>Multimedia Tools and Applications</ud2></strong> (SCI, IF=2.6), 2019.  <a href="https://github.com/Li-Chongyi/PAPERS/blob/master/Blind%20face%20images%20deblurring%20with%20enhancement2020-multimedia%20tools%20and%20applications.pdf" target="_blank"><font color="#1C86EE">[PDF]</font></a> </li> 
<li> Xiangyuan Gu, Jichang Guo, <strong>Chongyi Li</strong>, Lijun Xiao, A feature selection algorithm based on redundancy analysis and interaction weight, <strong><ud2>Applied Intelligence</ud2></strong> (SCI, IF=2.882), 2020. <a href="" target="_blank"><font color="#1C86EE">[PDF-Arxiv version]</font></a> <a href="" target="_blank"><font color="#1C86EE">[PDF-offical version]</font></a></li>  
<li> Saeed Anwar, Muhammad Tahir, <strong>Chongyi Li</strong>, et al., Image Colorization: A Survey and Dataset. <a href="https://arxiv.org/pdf/2008.10774.pdf" target="_blank"><font color="#1C86EE">[PDF--Arxiv Version]</font></a> </li>
</ol>    
  
<h4>
<a id="publications-J-pages" class="anchor" href="#publications-J-pages" aria-hidden="true"><span class="octicon octicon-link"></span></a>2019:</h4>

<ol>
<li> <strong>Chongyi Li</strong>,  Chunle Guo, Wenqi Ren, et al., An Underwater Image Enhancement Benchmark Dataset and Beyond, <strong><ud2>IEEE Transaction on Image Processing</ud2></strong> (SCI, IF=9.34), 2019. <a href="https://arxiv.org/pdf/1901.05495.pdf" target="_blank"><font color="#1C86EE">[PDF--Arxiv version]</font></a> <a href="https://ieeexplore.ieee.org/document/8917818" target="_blank"><font color="#1C86EE">[PDF-offical version]</font></a> <a href="https://li-chongyi.github.io/proj_benchmark.html" target="_blank"><font color="#1C86EE">[Project]</font></a></li>   
<li> <strong>Chongyi Li</strong>, Saeed Anwar, and Fatih Porikli, Underwater Scene Prior Inspired Deep Underwater Image and Video Enhancement, <strong><ud2>Pattern Recognition</ud2></strong> (SCI, IF=5.898), 2019. <a href="https://www.sciencedirect.com/science/article/pii/S0031320319303401" target="_blank"><font color="#1C86EE">[PDF-offical version]</font></a> <a href="https://arxiv.org/abs/1807.03528" target="_blank"><font color="#1C86EE">[PDF--Arxiv version]</font></a> <a href="https://li-chongyi.github.io/proj_underwater_image_synthesis.html" target="_blank"><font color="#1C86EE">[Project]</font></a></li>
<li> <strong>Chongyi Li</strong>, Chunle Guo, Jichang Guo, et al., PDR-Net: Perception-Inspired Single Image Dehazing Network with Refinement, <strong><ud2>IEEE Transaction on Multimedia</ud2></strong> (SCI, IF=5.452), 2019. <a href="https://ieeexplore.ieee.org/document/8792133" target="_blank"><font color="#1C86EE">[PDF]</font></a> </li>
<li> <strong>Chongyi Li</strong>, Runmin Cong, Junhui Hou, et al., Nested Network with Two-Stream Pyramid for Salient Object Detection in Optical Remote Sensing Images, <strong><ud2>IEEE Transaction on Geoscience and Remote Sensing</ud2></strong> (SCI, IF=4.662), 2019. <a href="https://ieeexplore.ieee.org/document/8793227" target="_blank"><font color="#1C86EE">[PDF]</font></a> <a href="https://li-chongyi.github.io/proj_optical_saliency.html" target="_blank"><font color="#1C86EE">[Project]</font></a></li>
<li> Miao Yang, Jintong Hu, <strong>Chongyi Li</strong>, et al., An In-depth Survey of Underwater Image Enhancement and Restoration, <strong><ud2>IEEE ACCESS</ud2></strong> (SCI,IF.3.244), 2019. <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8786104" target="_blank"><font color="#1C86EE">[PDF]</font></a> </li>
<li> Bo Wang and <strong>Chongyi Li</strong>, A visual hierarchical framework based model for underwater image enhancement, <strong><ud2>Frontiers of Computer Science</ud2></strong> (SCI, IF=1.105), 2019.  <a href="https://github.com/Li-Chongyi/PAPERS/blob/master/A%20visual%20hierarchical%20framework%20based%20model%20for%20underwater.pdf" target="_blank"><font color="#1C86EE">[PDF]</font></a> </li>  
<li> Xiangyuan Gu, Jichang Guo, Lijun Xiao, Tao Ming, and <strong>Chongyi Li</strong>, A feature selection algorithm based on equal interval division and minimal-redundancy–maximal-relevance, <strong><ud2>Neural Processing Letters</ud2></strong> (SCI, IF=2.591), 2019.  <a href="https://github.com/Li-Chongyi/PAPERS/blob/master/A%20visual%20hierarchical%20framework%20based%20model%20for%20underwater.pdf" target="_blank"><font color="#1C86EE">[PDF]</font></a> </li>
  

</ol>  
  
<h4>
<a id="publications-J-pages" class="anchor" href="#publications-J-pages" aria-hidden="true"><span class="octicon octicon-link"></span></a>2018:</h4>

<ol>

<li> Chunle Guo, <strong>Chongyi Li (co-first author, corresponding author)</strong>, Jichang Guo, et al., Hierarchical Features Driven Residual Learning for Depth Map Super-Resolution, <strong><ud2>IEEE Transaction on Image Processing</ud2></strong> (SCI, IF=9.34), 2018. <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8579111" target="_blank"><font color="#1C86EE">[PDF]</font></a> <a href="https://li-chongyi.github.io/proj_SR.html" target="_blank"><font color="#1C86EE">[Project]</font></a></li>
<li> <strong>Chongyi Li</strong>, Jichang Guo, Fatih Porikli, et al., A convolutional neural network cascade for single image dehazing, <strong><ud2>IEEE Access</ud2></strong> (SCI, IF=3.244), 2018.  <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8323372" target="_blank"><font color="#1C86EE">[PDF]</font></a> </li>
<li> <strong>Chongyi Li</strong>, Jichang Guo, Fatih Porikli, et al., LightenNet: a convolutional neural network for weakly illuminated image enhancement,  <strong><ud2>Pattern Recognition Letters (PRL)</ud2> </strong> (SCI, IF=1.995), 2018. <a href="http://www.porikli.com/mysite/pdfs/porikli%202018%20-%20LightenNet:%20a%20Convolutional%20Neural%20Network%20for%20weakly%20illuminated%20image%20enhancement.pdf" target="_blank"><font color="#1C86EE">[PDF]</font></a> <a href="https://li-chongyi.github.io/proj_lowlight.html" target="_blank"><font color="#1C86EE">[Project]</font></a></li> 
<li> <strong>Chongyi Li</strong>, Jichang Guo, Chunle Guo, Emerging from water: underwater image color correction based on weakly supervised color transfer, <strong><ud2>IEEE Signal Processing Letters (SPL)</ud2> </strong> (SCI, IF=2.528), 2018. <a href="https://github.com/Li-Chongyi/PAPERS/blob/master/Emerging%20From%20Water_Underwater%20Image%20Color%20Correction%20Based%20on%20Weakly%20Supervised%20Color%20Transfer%20.pdf" target="_blank"><font color="#1C86EE">[PDF]</font></a> <a href="https://li-chongyi.github.io/proj_Emerging_water.html" target="_blank"><font color="#1C86EE">[Project]</font></a></li>   

</ol>  
  
<h4>
<a id="publications-J-pages" class="anchor" href="#publications-J-pages" aria-hidden="true"><span class="octicon octicon-link"></span></a>2017:</h4>

<ol>

<li> <strong>Chongyi Li</strong>, Jichang Guo, Chunle Guo, et al., A hybrid method for underwater image correction,  <strong><ud2>Pattern Recognition Letters (PRL)</ud2> </strong> (SCI, IF=1.995), 2017. <a href="https://github.com/Li-Chongyi/PAPERS/blob/master/A%20hybrid%20method%20for%20underwater%20image%20correction.pdf" target="_blank"><font color="#1C86EE">[PDF]</font></a> </li>
  
<li>Yan Zhang, Jichang Guo, <strong>Chongyi Li</strong>, Image compressed sensing based on non-convex low-rank approximation,  <strong><ud2>Multimedia Tools and Applications (MTA)</ud2></strong> (SCI, IF=1.530), 2017. <a href="https://github.com/Li-Chongyi/PAPERS/blob/master/Image%20Compressed%20sensing%20based%20on%20non-convex%20low-rank%20approximation.pdf" target="_blank"><font color="#1C86EE">[PDF]</font></a> </li>
  
<li>Yan Zhang, Jichang Guo, <strong>Chongyi Li</strong>, Compressive sensing in wireless multimedia sensor networks based on low-rank approximation,  <strong><ud2>IEEE International Conference on Communications (ICC)<ud2></strong>, 2017. <a href="https://github.com/Li-Chongyi/PAPERS/blob/master/Compressive%20sensing%20in%20wireless%20multimedia%20sensor%20networks%20based%20on%20low-rank%20approximation.pdf" target="_blank"><font color="#1C86EE">[PDF]</font></a> </li>
  
</ol>
  
<h4>
<a id="publications-J-pages" class="anchor" href="#publications-J-pages" aria-hidden="true"><span class="octicon octicon-link"></span></a>2016:</h4>

<ol>

<li><strong>Chongyi Li</strong>, Jichang Guo, Runmin Cong, et al., Underwater image enhancement by dehazing with minimum information loss and histogram distribution prior, <strong><ud2>IEEE Transactions on Image Processing (TIP)</ud2></strong> (SCI, IF=9.34), 2016. <a href="https://github.com/Li-Chongyi/PAPERS/blob/master/Underwater%20Image%20Enhancement%20by%20Dehazing%20With%20Minimum%20Information%20Loss%20and%20Histogram%20Distribution%20Prior.pdf" target="_blank"><font color="#1C86EE">[PDF]</font></a> <a href="https://github.com/Li-Chongyi/TIP2016-code" target="_blank"><font color="#1C86EE">[Code]</font></a></li>
  
<li><strong>Chongyi Li</strong>, Jichang Guo, Bo Wang, et al., Single underwater image enhancement based on color cast removal and visibility restoration, <strong><ud2>Journal of Electronic Imaging (JEI)</ud2></strong> (SCI, IF=0.754), 2016. <a href="https://github.com/Li-Chongyi/PAPERS/blob/master/Single%20underwater%20image%20enhancement%20based%20on%20color%20cast%20removal%20and%20visibility%20restoration.pdf" target="_blank"><font color="#1C86EE">[PDF]</font></a> </li>
  
<li><strong>Chongyi Li</strong>, Jichang Guo, Shanji Chen, et al., Underwater image resstoration based on minimum information loss principle and optical properties of underwater imaging, <strong><ud2>IEEE International Conference on Image Processing (ICIP)</ud2></strong>, 2016. <a href="https://github.com/Li-Chongyi/PAPERS/blob/master/Underwater%20image%20restoration%20based%20on%20minimum%20information%20loss%20principle%20and%20optical%20properties%20of%20underwater%20imaging.pdf" target="_blank"><font color="#1C86EE">[PDF]</font></a> </li>
 
<li><strong>Chongyi Li</strong>, Jichang Guo, Yanwei Pang, et al., Single underwater image resstoration by blue-green channles dehazing and red channel correction, <strong><ud2>IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</ud2></strong>, 2016. <a href="https://github.com/Li-Chongyi/PAPERS/blob/master/Single%20underwater%20image%20restoration%20by%20blue-green%20channels%20dehazing%20and%20red%20channel%20correction.pdf" target="_blank"><font color="#1C86EE">[PDF]</font></a> </li>
  
<li>Runmin Cong, Ping Han, <strong>Chongyi Li</strong>, et al, Manmade target extraction based on multi-stage decision and its application for change detection in polarimetric synthetic aperture radar image, <strong><ud2>Journal of Electronic Imaging (JEI)</ud2></strong> (SCI, IF=0.754), 2016. <a href="https://github.com/Li-Chongyi/PAPERS/blob/master/Manmadetargetextractionbasedonmultistagedecisionanditsapplicationforchangedetectioninpolarimetricsyntheticapertureradarimage.pdf" target="_blank"><font color="#1C86EE">[PDF]</font></a> </li>
</ol>
  
<h4>
<a id="publications-J-pages" class="anchor" href="#publications-J-pages" aria-hidden="true"><span class="octicon octicon-link"></span></a>2015:</h4>

<ol>
  
<li> <strong>Chongyi Li</strong>, Jichang Guo, Underwater image enhancement by dehazing and color correction,  <strong><ud2>Journal of Electronic Imaging (JEI)</ud2></strong> (SCI, IF=0.754), 2016. <a href="https://github.com/Li-Chongyi/PAPERS/blob/master/Underwater%20image%20enhancement%20by%20dehazing%20and%20color%20correction.pdf" target="_blank"><font color="#1C86EE">[PDF]</font></a> </li>

<li>Bo Wang, Jichang Guo, Yan Zhang, <strong>Chongyi Li</strong>, Hierarchical feature concatenation-based kernel sparse representations for image categorization, <strong><ud2>The Visual Computer (TVC)</ud2></strong> (SCI, IF：1.468), 2016.  <a href="https://github.com/Li-Chongyi/PAPERS/blob/master/Hierarchical%20feature%20concatenation-based%20kernel%20sparse%20representations%20for%20image%20categorization.pdf" target="_blank"><font color="#1C86EE">[PDF]</font></a> </li>

</ol>
  
<h4>
<a id="publications-J-pages" class="anchor" href="#publications-J-pages" aria-hidden="true"><span class="octicon octicon-link"></span></a>Invited Talk:</h4>

<ol>
  
<li><strong>Underwater Image Enhancement: Challenges, Benchmarks, and Solutions</strong>. Invited Talk, Center of Digital Media Information Processing, Beijing Jiaotong University. <a href="https://github.com/Li-Chongyi/PAPERS/blob/master/BeijiaoPoster.jpg" target="_blank"><font color="#ff0000">[Poster]</font></a></a></li>  
<li><strong>ASIF-Net: Attention Steered Interweave Fusion Network for RGB-D salient Object Detection</strong>. Invited Talk, ShenZhen Institutes of Advanced Technology, Chinese Academy of Sciences. <a href="https://github.com/Li-Chongyi/PAPERS/blob/master/talk_poster1.jpg" target="_blank"><font color="#ff0000">[Poster]</font></a></a></li>  


</ol>
  
<h4>
<a id="publications-J-pages" class="anchor" href="#publications-J-pages" aria-hidden="true"><span class="octicon octicon-link"></span></a>Patent:</h4>

<ol>
  
<li> ZL 2016 1 0606187.9 <a href="https://github.com/Li-Chongyi/PAPERS/blob/master/%E5%8F%91%E6%98%8E%E4%B8%93%E5%88%A9%E8%AF%81%E4%B9%A6-%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%E6%9C%80%E4%BC%98%E5%8C%96%E9%A2%9C%E8%89%B2%E4%BF%AE%E6%AD%A3%E5%92%8C%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%B0%B4%E4%B8%8B%E5%9B%BE%E5%83%8F%E5%A4%8D%E5%8E%9F%E6%96%B9%E6%B3%95.jpg" target="_blank"><font color="#1C86EE">[PDF]</font></a> </li>
<li> ZL 2016 1 1028224.9 <a href="https://github.com/Li-Chongyi/PAPERS/blob/master/%E5%8F%91%E6%98%8E%E4%B8%93%E5%88%A9%E8%AF%81%E4%B9%A6-%E5%9F%BA%E4%BA%8E%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%92%8C%E5%85%88%E9%AA%8C%E4%BF%A1%E6%81%AF%E7%9A%84%E5%9B%BE%E5%83%8F%E5%8E%BB%E9%9B%BE%E6%96%B9%E6%B3%95.pdf" target="_blank"><font color="#1C86EE">[PDF]</font></a> </li>
<li> ZL 2016 1 0244589.9 <a href="https://github.com/Li-Chongyi/PAPERS/blob/master/%E5%8F%91%E6%98%8E%E4%B8%93%E5%88%A9%E8%AF%81%E4%B9%A6_%E4%B8%80%E7%A7%8D%E7%AB%8B%E4%BD%93%E8%A7%86%E8%A7%89%E6%98%BE%E8%91%97%E6%80%A7%E6%A3%80%E6%B5%8B%E6%96%B9%E6%B3%95.pdf" target="_blank"><font color="#1C86EE">[PDF]</font></a> </li>

  
</ol>
</div>


</section>

</div>
<script src="../javascripts/scale.fix.js"></script>
</body>
</html>
