<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Emerging From Water</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <meta name="viewport" content="width=device-width">
  </head>
  <body>
    <div class="wrapper">
<header>
<h7>Chongyi Li</h7><br><br>
<div>
<img src="sub_img/IMG_7689.jpg" border="0" width="80%"><br></div><br>

  
<p>
<small>lichongyi25 @ gmail.com </small><br><br>
<a href="https://github.com/Li-Chongyi" target="_blank">[GitHub]</a>  
<a href="http://dblp.uni-trier.de/pers/hd/l/Li:Chongyi" target="_blank">[DBLP]</a>  <br>
<a href="https://scholar.google.com/citations?user=1_I0P-AAAAAJ&hl=zh-CN" target="_blank">[Google Scholar]</a> <br>
</p> <br>
<p class="view"><a href="https://li-chongyi.github.io/">Homepage</a></p>
<p class="view"><a href="sub_publication.html">Publications</a></p>
<p class="view"><a href="sub_projects.html">Projects</a></p>
</header>


      <section>

<h2>
<a id="project_title" class="anchor" href="#project_title" aria-hidden="true"><span class="octicon octicon-link"></span></a>Emerging From Water</h2>




<h4>
<a id="Introduction-page" class="anchor" href="#Introduction-pages" aria-hidden="true"><span class="octicon octicon-link"></span></a>Introduction:</h4>
<div style="text-align: justify; display: block; margin-right: auto;">
<p>Underwater vision suffers from severe effects due to selective attenuation and scattering when light propagates
through water. Such degradation not only affects the quality of underwater images but limits the ability of vision tasks. Different
from existing methods which either ignore the wavelength dependence on the attenuation or assume a specific spectral profile, we
tackle color distortion problem of underwater images from a new view. In this letter, we propose a weakly supervised color transfer
method to correct color distortion. The proposed method relaxes the need for paired underwater images for training and allows the
underwater images being taken in unknown locations. Inspired by Cycle-Consistent Adversarial Networks, we design a multi-term loss function including adversarial loss, cycle consistency
loss, and SSIM (Structural Similarity Index Measure) loss, which makes the content and structure of the outputs same as the inputs,
meanwhile the color is similar to the images which were taken without the water. Experiments on underwater images captured
under diverse scenes show that our method produces visually pleasing results, even outperforms the art-of-the-state methods. Besides, our method can improve the performance of vision tasks.
</p>

<div style="text-align: center; display: block; margin-right: auto;">
<img src="sub_img/Emerging_results.png" border="0" width="600"><br></div><br>


<hr />
<h4>Paper:</h4>
    
<p>
  Chongyi Li, Jichang Guo, Chunle Guo, 
  <strong>Emerging from Water: Underwater Image Color Correction Based on Weakly Supervised Color Transfer</strong>. 
  <a href="https://arxiv.org/pdf/1710.07084.pdf"><font color="#ff0000">[arXiv]</font></a>
</p>

 
<hr />
<h4>Results and User Study:</h4>
<div style="text-align: justify; display: block; margin-right: auto;">
<p>
 For the user study, the results of different methods were randomly displayed on the screen and compared with the corresponding raw underwater images. After that, we invited 10 participants who had experience with image processing to score results. There was no time limitation for each participant. Moreover, the participants did not know which results were
 produced by our method. The scores ranged from 1 (worst) to 8 (best). As baseline, we set the scores of raw underwater images to 3. We expected the good result has high contrast and visibility, abundant details, in especial the color as if the image was taken without the water. On the contrary, the bad result has low visibility, over-enhanced regions, serious artifacts and noise, and inauthentic color.
 <ud2>Results and Scores (~55MB)</ud2> <a href="https://github.com/Li-Chongyi/Emerging-from-water-More-results" target="_blank"><font color="#ff0000">[Download Link].</font></a>
</p>
<hr />
        
<h4>References:</h4>

<p>

<li> A. Galdran, D. Pardo, and A. Picn, “Automatic red-channel underwater image restoration,” J. Vis. Commun. Image R., vol. 26, pp.132-145, 2015.</li>

<li> C. Li, C. Ji, R. Cong, and et al.“Underwater image enhancement by dehazing with minimum information loss and histogram distribution prior,” IEEE Trans. Image Process., vol. 25, no. 12, pp.5664-5677, 2016.</li>

<li> Y. Peng and P. Cosman, “Underwater image restoration based on image blurriness and light absorption,” IEEE Trans. Image Process., vol. 26, no. 4, pp.1579-1594, 2017.</li>

<li> G. Buchsbaum, “A spatial processor model for object colour perception,” J. of The Franklin Inst., vol. 310, no. 1, pp. 1-26, 1980.</li>

<li> Y. Zhu, T. Park, P. Isola, and et al., “Unpaired image-to-image translation using cycle-consistent adversarial networks,” arXiv:1703.10593, 2017.</li>

<li> Y. Gong and F. Sbalzarini, “A natural-scene gradient distribution prior and its application in light-microscopy image processing,” IEEE J. Sel. Topics Signal Process., vol 10, no. 1, pp. 99-114, 2016.</li>
 </p>
 



      </section>

    </div>
    <script src="../../javascripts/scale.fix.js"></script>
  </body>
</html>
